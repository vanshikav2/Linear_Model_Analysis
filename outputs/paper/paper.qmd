---
title: "Investigating the Mean of the True Data Generating Process"
subtitle: " Addressing Data Integrity Issues"
author: 
  - Vanshika Vanshika
thanks: "Code and data are available at: https://github.com/vanshikav2/Linear_Model_Analysis."
date: today
date-format: long
abstract: "In this paper, we investigated whether the mean of a cleaned dataset, originating from a flawed instrument, exceeded zero. Through visual analysis of histograms and boxplots, we observed a concentration of values around zero, with a notable threshold at one. Despite data integrity issues, our findings shed light on the dataset's distribution and underscore the importance of rigorous data cleaning processes. Understanding the impact of data quality on analysis outcomes is critical for ensuring the reliability of research findings in various domains."
format: pdf
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(ggplot2)
library(here)

# Read cleaned dataset
cleaned_data <- read.csv(here("outputs/data", "analysis_data.csv"), header = FALSE, skip = 2)

```


# Introduction

In this analysis, we explore the impact of issues encountered during data cleaning on our understanding of the true data generating process. We examine histograms and boxplots of the cleaned dataset to assess whether the mean of the true data generating process is greater than 0. Additionally, we discuss the implications of the issues and propose steps to ensure data integrity in future analyses.

The remainder of this paper is structured as follows. @sec-data....



# Data {#sec-data}

We begin by reading the cleaned dataset from the CSV file and calculating the mean of the dataset. Next, we create histograms and boxplots to visualize the distribution of the cleaned data and overlay the mean value for comparison as seen in @fig-bills.


```{r}
#| label: fig-bills
#| fig-cap: Mean of Cleaned Data
#| echo: false



# Calculate mean of the cleaned dataset
mean_cleaned <- mean(cleaned_data$V1)

# Create histogram of cleaned data
histogram <- ggplot(data = data.frame(x = cleaned_data$V1), aes(x = x)) +
  geom_histogram(binwidth = 0.2, fill = "skyblue", color = "black", alpha = 0.7) +
  labs(title = "Histogram of Cleaned Data",
       x = "Value", y = "Frequency") +
  geom_vline(xintercept = mean_cleaned, color = "red", linetype = "dashed") +
  theme_minimal()

# Display plots
print(histogram)

```
### Data Cleaning

Before delving into our analysis, it is imperative to shed light on the intricacies of the data cleaning process.We used R [@citeR] for data cleaning and processing, utilizing packages like tidyverse [@tidy] for cleaning column names. Other packages used includes `ggplot2` [@ggplot], and `here` [@here]. Unknown to us, the instrument used for data collection harbored a flaw, leading to the inadvertent repetition of the final 100 observations, which are duplicates of the first 100. Additionally, during the cleaning process, our research assistant inadvertently altered half of the negative values to be positive and adjusted the decimal place for values between 1 and 1.1. These inadvertent modifications necessitated thorough scrutiny to ensure the integrity of our subsequent analysis.

### Analysis Approach

To ascertain whether the mean of the true data generating process is greater than 0, we employed visual analysis techniques. Specifically, we constructed a histogram of the cleaned dataset to gain insights into its distribution. Additionally, we created a boxplot to further elucidate the central tendency and variability of the dataset. These graphical representations allowed us to discern any discernible patterns, anomalies, or trends that might inform our understanding of the underlying data generating process.



# Results

Upon meticulous examination of the histogram and boxplot of the cleaned dataset, several notable observations emerged. The histogram revealed a peak frequency around 0, indicative of a substantial proportion of values clustered around this central point. This distribution pattern suggests that the dataset exhibits symmetry around 0, with values on either side being similarly represented. Notably, the presence of the red dashed line at Value = 1 on the histogram signifies a potential threshold or target value relevant to our analysis.


# Discussion

The findings from our analysis provide valuable insights into the distribution of the cleaned dataset and its implications for evaluating the mean of the true data generating process. The observed concentration of values around 0 raises intriguing questions about the underlying data-generating mechanism and its relationship to our hypothesis regarding the mean exceeding 0. Additionally, the presence of the threshold value at 1 warrants further investigation to discern its significance in the context of our analysis.

### Impact of Data Integrity Issues

The inadvertent issues encountered during the data cleaning process had notable implications for our analysis. The instrument memory issue, resulting in the duplication of observations, introduced bias into the dataset, potentially skewing our assessment of the mean. Furthermore, the inadvertent alterations to negative values and adjustments to decimal places undermined the integrity of the dataset, necessitating careful consideration to mitigate their impact on our findings.

Steps to Ensure Data Integrity: 
To ensure the integrity of future analyses and preemptively flag potential issues, several proactive measures can be implemented:

1. Robust Quality Control Procedures: Establish stringent quality control protocols to detect and rectify issues during data collection and preprocessing.
2. Automated Validation Checks: Implement automated validation checks to flag anomalies and inconsistencies in the dataset, facilitating timely intervention.
3. Documentation and Transparency: Maintain comprehensive documentation of data collection and cleaning procedures, enhancing transparency and reproducibility.
4. Peer Review Processes: Incorporate peer review mechanisms to validate findings and identify potential sources of bias or error, fostering rigor and accountability in the analysis process.

By adopting these measures, researchers can bolster the reliability and validity of their analyses, thereby enhancing confidence in the resulting findings and facilitating meaningful contributions to the body of knowledge in their respective domains.

\newpage


# References


